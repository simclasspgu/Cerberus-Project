from langchain_ollama import OllamaLLM

def get_llm():
    return OllamaLLM(
        model="llama2",   
        temperature=0,
        verbose=True
    )
